library(lubridate)
?duplicated
bob <- duplicated(july)
multi <- july[bob,]
sum(bob)
rm(bob, multi)
bob <- duplicated(july$`E-mail address`)
sum(bob)
multi <- july[duplicated(july$`E-mail address`),]
View(multi)
table(multi$`E-mail address`)
dup <- data.frame(as.numeric(duplicated(july$`E-mail address`))) #creates df with binary var for duplicated rows
colnames(dup) <- c("dup") #renames column for simplicity
df2 <- cbind(july, dup) #bind to original df
df3 <- subset(df2, dup == 1) #subsets df using binary var for duplicated`
View(df3)
library(dplyr)
?distinct
july[(duplicated(july$`E-mail address`, fromLast = FALSE) | duplicated(july$`E-mail address`, fromLast = TRUE)),]
multi <- july[(duplicated(july$`E-mail address`, fromLast = FALSE) |
duplicated(july$`E-mail address`, fromLast = TRUE)),]
View(multi)
table(multi$`E-mail address`)
View(multi)
?order
sorted <- multi[order(`E-mail address`)]
sorted <- multi[order(`E-mail address`),]
sorted <- multi[order(`E-mail address`),]
names(multi)
sorted <- multi[order(multi$`E-mail address`),]
View(sorted)
sorted$Timestamp[2] - sorted$Timestamp[1]
mmm <- diff(sorted$Timestamp)
mmm
sorted$timediff <- 0
sorted$timediff[2:123] <- mmm
View(sorted)
sorted[,c(1,7)]
sorted[,c(1,2,7)]
sorted[1:123,c(1,2,7)]
sorted$timediff <- ifelse(sorted$timediff<0, NA, sorted$timediff)
View(sorted)
sorted$timediff[c(1,3,7,9,11,13,15,17,21,27,29,31,33,35,38,41,43,46,48,50,52,54,57,59,61,63,65,67,69,71,73,75,77,79,82,84,86,90,92,97,99,102,104,106,109,111,113,115,117,119,121)] <- NA
View(sorted)
hist(sorted$timediff)
hist(sorted$timediff, xlim=c(0,100))
hist(sorted$timediff, xlim=c(0,1000))
sum(sorted$timediff<100)
sum(sorted$timediff<100, na.rm=TRUE)
sum(sorted$timediff<60, na.rm=TRUE)
sum(sorted$timediff<30, na.rm=TRUE)
sum(sorted$timediff<15, na.rm=TRUE)
sorted$`E-mail address`[sorted$timediff<30]
sorted$`E-mail address`[sorted$timediff<30, na.rm=TRUE]
!is.na(sorted$`E-mail address`[sorted$timediff<30])
sorted$`E-mail address`[!is.na(sorted$timediff) & sorted$timediff<30]
sorted$`Country`[!is.na(sorted$timediff) & sorted$timediff<30]
source('C:/Users/eric/OneDrive/isec-panopto-graphs.r', echo=TRUE)
source('C:/Users/eric/OneDrive/isec-panopto-graphs.r', echo=TRUE)
source('C:/Users/eric/OneDrive/isec-panopto-graphs.r', echo=TRUE)
source('C:/Users/eric/OneDrive/isec-panopto-graphs.r', echo=TRUE)
View(ell)
source('C:/Users/eric/OneDrive/isec-panopto-graphs.r', echo=TRUE)
source('P:/multiple downloads within half hour.R', echo=TRUE)
source('P:/multiple downloads within half hour.R', echo=TRUE)
length(unique(july$`E-mail address`))
fast.double.download <- sorted$`E-mail address`[!is.na(sorted$timediff) & sorted$timediff<30]    # number of subsequent downloads within half hour of first
length(fast.double.download)/length(unique(july$`E-mail address`)) * 100
fast.double.download <- sorted$`E-mail address`[!is.na(sorted$timediff) & sorted$timediff<20]    # number of subsequent downloads within half hour of first
length(fast.double.download)/length(unique(july$`E-mail address`)) * 100
fast.double.download <- sorted$`E-mail address`[!is.na(sorted$timediff) & sorted$timediff<15]    # number of subsequent downloads within half hour of first
length(fast.double.download)/length(unique(july$`E-mail address`)) * 100
round(length(fast.double.download)/length(unique(july$`E-mail address`)) * 100, 1)
install.packages(c("reticulate", "rgdal"))
library(lubridate)
min(july$Timestamp)
max(july$Timestamp)
range(july$Timestamp)
days(max(july$Timestamp)-min(july$Timestamp))
max(july$Timestamp)-min(july$Timestamp)
round(max(july$Timestamp)-min(july$Timestamp))
timespan <- round(max(july$Timestamp)-min(july$Timestamp))
downloads <- length(july$Timestamp)
downloads.per.day <- downloads/timespan
persons <- length(unique(july$`E-mail address`))
fast.double.download <- sorted$`E-mail address`[!is.na(sorted$timediff) & sorted$timediff<15]    # number of subsequent downloads within half hour of first
pct.double.down <- round(length(fast.double.download)/length(unique(july$`E-mail address`)) * 100, 1)
leg <- c("Total downloads",
"Downloads per day",
"Unique downloads",
"Second download within 15min",
"Percent second download")
stats <- c(downloads, downloads.per.day, persons, fast.double.download, pct.double.down)
output <- data.frame(leg,stats)
knitr::kable(output, caption="Distance 7.2 download statistics")
str(timespan)
timespan <- as.numeric(round(max(july$Timestamp)-min(july$Timestamp), units="days")
downloads.per.day <- downloads/timespan
timespan <- as.numeric(round(max(july$Timestamp)-min(july$Timestamp), units="days"))
timespan <- as.numeric(round(max(july$Timestamp)-min(july$Timestamp)), units="days")
downloads <- length(july$Timestamp)
downloads.per.day <- downloads/timespan
persons <- length(unique(july$`E-mail address`))
fast.double.download <- sorted$`E-mail address`[!is.na(sorted$timediff) & sorted$timediff<15]    # number of subsequent downloads within half hour of first
pct.double.down <- round(length(fast.double.download)/length(unique(july$`E-mail address`)) * 100, 1)
leg <- c("Total downloads",
"Downloads per day",
"Unique downloads",
"Second download within 15min",
"Percent second download")
stats <- c(downloads, downloads.per.day, persons, fast.double.download, pct.double.down)
output <- data.frame(leg,stats)
leg
stats
stats <- c(downloads, round(downloads.per.day,2),
persons, length(fast.double.download), pct.double.down)
output <- data.frame(leg,stats)
knitr::kable(output, caption="Distance 7.2 download statistics")
install.packages(c("FNN", "kernlab", "scales", "XML"))
install.packages(c("fansi", "pkgconfig", "processx", "Quandl", "RcppArmadillo", "rlang"))
install.packages(c("lme4", "processx", "RcppArmadillo", "rlang", "sandwich", "VGAM", "XML"))
devtools::install_github("dtkaplan/cleanr")
devtools::install_github("dtkaplan/checkr")
devtools::install_github("redpen-cc/redpen")
devtools::install_github("lionel-/redpen")
devtools::install_github("dtkaplan/checkr")
devtools::install_github("dtkaplan/checkr", build_vignette=TRUE)
devtools::install_github("dtkaplan/checkr", build_vignette=TRUE, force=TRUE)
install.packages("mosaic")
devtools::install_github("dtkaplan/checkr", build_vignette=TRUE, force=TRUE)
library(checkr)
check_exer_1_v0 <- function(USER_CODE) {
code <- for_checkr(USER_CODE)
desired <- rep(1:4, each = 3)
line_where(code, insist(all(V == desired), "Your vector is {{V}}. That is not the result asked for."))
}
check_exer_1_v0("c(1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4)")
bob <- check_exer_1_v0("c(1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4)")
str(bob)
check_exer_1_v1 <- function(USER_CODE) {
code <- for_checkr(USER_CODE)
line_binding(code, rep(1:4, each = 3), passif(TRUE, "Just what I wanted!"),
message = "Sorry. Not exactly what I was looking for.")
}
check_exer_1_v1("c(1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4)")$message
check_exer_1_v1("x <- rep(1:4,each=3); x")$message
check_exer_1_v1("x <- 1:4; rep(x, each = 3)")$message
check_exer_1_v1("sort(rep(1:4, 3))")$message
check_exer_1_v2 <- function(USER_CODE) {
code <- for_checkr(USER_CODE)
desired <- rep(1:4, each = 3)
line_a <- line_calling(code, rep, message = "I'm not seeing where you used `rep()`.")
t1 <- vector_arg(line_a, insist(all(V == 1:4), "Where did you use `1:4`?"))
if (failed(t1)) return(t1)
line_where(code, insist(all(V == desired), "Your vector is {{V}}. That is not the result asked for."))
}
check_exer_1_v2("x <- 1:4; rep(x, each = 3)")
check_exer_1_v2("sort(rep(1:4, 3))")
sort(rep(1:4, 3))
rep(1:4,3)
check_exer_1_v3 <- function(USER_CODE) {
code <- for_checkr(USER_CODE)
desired <- rep(1:4, each = 3)
LineA <- line_calling(code, rep, message = "I'm not seeing where you used `rep()`.")
t1 <- vector_arg(LineA, insist(all(V == 1:4), "Where did you use `1:4`?"))
if (failed(t1)) return(t1)
rep_call <- arg_calling(LineA, rep) # in case rep() is buried in another function application, e.g. 1 * rep()
t2 <- named_arg(rep_call, "each",
insist(V == 3, "Remember, you want 12 elements in the output made from the 4 elements in the input"),
message = "See what use you can make of the `each` argument to rep().")
if (failed(t2)) return(t2)
line_where(code, insist(all(V == desired), "Your vector is {{V}}. That is not the result asked for."))
}
check_exer_1_v3("sort(rep(1:4, 3))")
check_exer_1_v3("x <- 1:4; rep(x, each = 3)")
check_exer_1_v3("rep(c(1,2,3,4), each=3)")
s1 <- quote(Circuits <- read.csv("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s2 <- quote(Circuits <- load("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s3 <- quote(read.csv("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s4 <- quote(bees <- read.csv("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s1
eval(s1)
rm(s1)
rm(Circuits)
s1 <- quote(Circuits <- read.csv("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s2 <- quote(Circuits <- load("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s3 <- quote(read.csv("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s4 <- quote(bees <- read.csv("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
check_bee_data <- function(USER_CODE) {
code <- for_checkr(USER_CODE)
# The messages
m1 <- "Right!"
m2 <- "Notice that the filename has a CSV extension. `{{F}}` is for reading RDA files. Try `read.csv()` instead."
m3 <- "Remember to store the contents of the data file under the name `Circuits`."
m4 <- "Store the data under the name `Circuits`, not `{{Z}}`."
browser()
result <- line_where(code,
passif(Z == "Circuits"),
failif(Z == "", m3),
failif(TRUE, m4))
return(result) # return the result of the checking
}
check_bee_data(s3)
result
check_bee_data(s4)
result
check_bee_data(s2)
result
install.packages("tinytex")
monteverde <- read.csv("C:/Users/eric/Documents/GitHub/stand-intermed-2018/R_tutorial/ducknests.csv")
monteverde$Area <- 45199339
est.hn <- ds(data=monteverde, key='hn')
library(Distance)
monteverde$Area <- 45199339
est.hn <- ds(data=monteverde, key='hn')
head(monteverde)
monteverde$Effort <- 1000
est.hn <- ds(data=monteverde, key='hn')
summary(est.hn)
20000*4.8
monteverde$Effort <- 128750
est.hn <- ds(data=monteverde, key='hn')
head(monteverde)
summary(est.hn)
source('~/.active-rstudio-document', echo=TRUE)
est.hn <- ds(data=monteverde, key='hn',
convert.units = .001)
head(monteverde)
summary(est.hn)
est.hn <- ds(data=monteverde, key='hn',
convert.units = .000001)
summary(est.hn)
est.hn <- ds(data=monteverde, key='hn',
convert.units = 1)
summary(est.hn)
source('~/.active-rstudio-document', echo=TRUE)
str(est.hn$ddf$ds$par)
exp(est.hn$ddf$ds$par)
exp(est.hn$ddf$ds$par) * 3.28084
install.packages(c("car", "digest"))
install.packages(c("callr", "plotrix", "wordcloud"))
install.packages(c("ggpubr", "tinytex", "xtable"))
install.packages(c("chron", "later"))
library(Distance)
data(minke)
View(minke)
minke.strat <- ds(data=minke, formula=~Region.Label)
summary(minke.strat)
summary(minke.strat)
pooled <- ds(data=minke)
summary(pooled)
exp(-.3514199)
library(readdst)
strat <- convert_project("C:/Users/eric/Documents/stratify-testbed/Stratify example")
R
version
library(Distance)
summary(ds(data=minke))
data(minke)
summary(ds(data=minke))
install.packages(c("digest", "whoami", "xts"))
julaugsep <- read.csv("P:/Distance 7.2 download form.csv")
View(julaugsep)
multi <- julaugsep[(duplicated(julaugsep$`E-mail address`, fromLast = FALSE) |
duplicated(julaugsep$`E-mail address`, fromLast = TRUE)),]
sorted <- multi[order(multi$`E-mail address`),]
sorted$timediff <- 0
mmm <- diff(sorted$Timestamp)
View(multi)
multi <- julaugsep[(duplicated(julaugsep$`E-mail address`, fromLast = FALSE) |
duplicated(julaugsep$`E-mail address`, fromLast = TRUE)),]
sorted <- multi[order(multi$`E-mail address`),]
View(multi)
names(julaugsep)
multi <- julaugsep[(duplicated(julaugsep$E.mail.address, fromLast = FALSE) |
duplicated(julaugsep$E.mail.address, fromLast = TRUE)),]
sorted <- multi[order(multi$E.mail.address),]
sorted$timediff <- 0
mmm <- diff(sorted$Timestamp)
mmm
julaugsep <- read.csv("P:/Distance 7.2 download form.csv", stringsAsFactors = FALSE)
multi <- julaugsep[(duplicated(julaugsep$E.mail.address, fromLast = FALSE) |
duplicated(julaugsep$E.mail.address, fromLast = TRUE)),]
sorted <- multi[order(multi$E.mail.address),]
sorted$timediff <- 0
mmm <- diff(sorted$Timestamp)
View(sorted)
library(lubridate)
library(readxl)
library(lubridate)
julaugsep <- read_xlsx("P:/Distance 7.2 download form.xlsx", stringsAsFactors = FALSE)
julaugsep <- read_xlsx("P:/Distance 7.2 download form.xlsx")
multi <- julaugsep[(duplicated(julaugsep$E.mail.address, fromLast = FALSE) |
duplicated(julaugsep$E.mail.address, fromLast = TRUE)),]
names(julaugsep)
multi <- julaugsep[(duplicated(julaugsep$`E-mail address`, fromLast = FALSE) |
duplicated(julaugsep$`E-mail address`, fromLast = TRUE)),]
sorted <- multi[order(multi$`E-mail address`),]
sorted$timediff <- 0
mmm <- diff(sorted$Timestamp)
View(sorted)
str(julaugsep)
mmm <- diff(sorted$Timestamp)
str(ssorted)
str(sorted)
julaugsep <- read_xlsx("P:/Distance 7.2 download form.xlsx",
col_types = c("date", "text", "skip", "text", "skip", "skip"))
warnings()
View(julaugsep)
julaugsep <- read_xlsx("P:/Distance 7.2 download form.xlsx")
julaugsep <- read_xlsx("P:/Distance 7.2 download form.xlsx")
julaugsep$time <- strptime(julaugsep$Timestamp, "%m/%d/%y %H:%M:%S")
View(julaugsep)
julaugsep$time <- strptime(substr(julaugsep$Timestamp, start = 1, stop = 10), "%m/%d/%y %H:%M:%S")
View(julaugsep)
julaugsep$time <- strptime(substr(julaugsep$Timestamp, start = 1, stop = 19), "%m/%d/%y %H:%M:%S")
strptime(substr(julaugsep$Timestamp, start = 1, stop = 19), "%m/%d/%y %H:%M:%S")
substr(julaugsep$Timestamp, start = 1, stop = 19)
tom <- substr(julaugsep$Timestamp, start = 1, stop = 19)
julaugsep$time <- strptime(substr(julaugsep$Timestamp, start = 1, stop = 10), "%y/%m/%d %H:%M:%S")
View(julaugsep)
julaugsep$time <- strptime(substr(julaugsep$Timestamp, start = 1, stop = 10), "%Y/%m/%d %H:%M:%S")
head(tom)
julaugsep$time <- strptime(substr(julaugsep$Timestamp, start = 1, stop = 19), "%Y/%m/%d %H:%M:%S ")
View(julaugsep)
multi <- julaugsep[(duplicated(julaugsep$`E-mail address`, fromLast = FALSE) |
duplicated(julaugsep$`E-mail address`, fromLast = TRUE)),]
sorted <- multi[order(multi$`E-mail address`),]
sorted$timediff <- 0
mmm <- diff(sorted$time)
mmm
sorted$timediff[2:280] <- mmm
View(sorted)
sorted$timediff[2:281] <- mmm
sorted$timediff <- ifelse(sorted$timediff<0, NA, sorted$timediff)
View(sorted)
sorted$timediff[c(1,3,7,9,11,13,15,17,19,21,23,25,31,33,35,41,43,46,48,
50,52,54,56,58,60,62,65,67,70,72,74,78,80,83,87,89,91,93,95,
97,99,101,103,105,107,109,112,116,118,121,123,126,128,130,132,134,136,138,141,
143,145,147,150,152,154,156,158,160,132,134,166,168,171,173,175,177,180,182,184,187,
189,193,195,197,199,201,203,207,209,211,213,216,218,223,225,228,230,232,235,
237,239,242,244,246,248,250,252,254,256,258,260,262,264,267,269,271,274,276,280)] <- NA   # first downloads by individual
timespan <- as.numeric(round(max(julaugsep$Timestamp)-min(julaugsep$Timestamp)), units="days")
timespan <- as.numeric(round(max(julaugsep$time)-min(julaugsep$time)), units="days")
downloads <- length(julaugsep$time)
downloads.per.day <- downloads/timespan
persons <- length(unique(julaugsep$`E-mail address`))
fast.double.download <- sorted$`E-mail address`[!is.na(sorted$timediff) & sorted$timediff<15]    # number of subsequent downloads within half hour of first
pct.double.down <- round(length(fast.double.download)/length(unique(julaugsep$`E-mail address`)) * 100, 1)
leg <- c("Total downloads",
"Downloads per day",
"Unique downloads",
"Second download within 15min",
"Percent second download")
stats <- c(downloads, round(downloads.per.day,2),
persons, length(fast.double.download), pct.double.down)
output <- data.frame(leg,stats)
knitr::kable(output, caption="Distance 7.2 download statistics")
hist(sorted$timediff)
fast.double.download <- sorted$`E-mail address`[!is.na(sorted$timediff) & sorted$timediff<900]    # number of subsequent downloads within half hour of first
pct.double.down <- round(length(fast.double.download)/length(unique(julaugsep$`E-mail address`)) * 100, 1)
leg <- c("Total downloads",
"Downloads per day",
"Unique downloads",
"Second download within 15min",
"Percent second download")
stats <- c(downloads, round(downloads.per.day,2),
persons, length(fast.double.download), pct.double.down)
output <- data.frame(leg,stats)
knitr::kable(output, caption="Distance 7.2 download statistics")
hist(sorted$/900)
hist(sorted$timediff/900)
install.packages("odbc")
install.packages(c("tm", "tm.plugin.mail"))
source('~/.active-rstudio-document', echo=TRUE)
zog <- all.sent[[1:10]]
all.sent[[1]]
all.sent[[1]]$content
all.sent[[1]]$meta$datetimestamp
library(lubridate)
bob <- all.sent$meta$datestamp > "2018-06-01"
bob
all.sent[[8000]]$meta$datetimestamp
bob <- all.sent[8000:8334]
View(bob)
bob$meta$author
bob$content
bob[[]]$content
tmp <- lapply(unlist(summer,recursive=FALSE), `[[`,2)
summer <- all.sent[8000:8334]
tmp <- lapply(unlist(summer,recursive=FALSE), `[[`,2)
View(tmp)
tm2 <- lapply(unlist(tmp), `[[`, `header`)
tm2 <- lapply(unlist(tmp), `[[`, `heading`)
tm2 <- lapply(unlist(tmp), `[[`, "heading")
tm2 <- lapply(unlist(tmp), `[[`, 4)
tm2 <- lapply(unlist(tmp), `[`, 4)
tm2
View(tmp)
tm2 <- lapply(unlist(tmp), `[[`, 4)
tm2 <- lapply(tmp, `[[`, 4)
View(tm2)
tmp <- lapply(unlist(summer,recursive=FALSE), `[[`,2)
tm2 <- unlist(lapply(tmp, `[[`, 4))
tm2[1:5]
str(tm2)
tm2 <- unname(unlist(lapply(tmp, `[[`, 4)))
head(tm2)
library(tm)
library(tm.plugin.mail)
# point the tm corpus machinery to the mbox file and let it know the timestamp format since it varies
all.sent <- VCorpus(
MBoxSource("C:/Users/eric/empty/sent"),
readerControl = list(
reader = readMail()
)
)
all.sent[[8100]]$content
all.sent.nosig <- removeSignature(all.sent)
class(all.sent)
nosig <- lapply(all.sent, FUN=removeSignature(x))
nosig <- lapply(all.sent, function(x) removeSignature(x))
nosig[[8100]]$content
nocitation <- lapply(all.sent, function(x) removeCitation(x))
nocitation[[8100]]$content
nomult <- lapply(all.sent, function(x) removeMultipart(x))
nomult[[8100]]$content
nomultsig <- lapply(nomult, function(x) removeSignature(x))
nomultsig[[8100]]$content
none <- lapply(nomultsig, function(x) removeCitation(x))
none[[8100]]$content
?save
getwd()
none[[8100]]$meta$header$To
save(none, file = "office-sent.Rdata")
getwd()
library(rmarkdown)
draft("myslides.Rmd", template="metropolis", package="binb", edit=FALSE)
getwd()
library(tint)
install.packages(c("ape", "cli", "doParallel"))
getwd()
!TRUE
library(ggplot2)
# Import Amakihi data
amakihi <- read.csv(file="https://synergy.st-andrews.ac.uk/ds-manda/files/2016/11/amakihi.csv")
# Basic histogram
ggplot(amakihi, aes(x=distance)) + geom_histogram(binwidth=1)
# Histogram with lots of bins and truncation at 82.5
ggplot(amakihi[amakihi$distance<82.5], aes(x=distance)) +
geom_histogram(binwidth=2.5)
hist(amakihi$distance[amakihi$distance<82.5,], breaks=33, main="Truncation 82.5",xlab = "Distance (m)")
# Histogram with lots of bins and truncation at 82.5
ggplot(amakihi[amakihi$distance<82.5,], aes(x=distance)) +
geom_histogram(binwidth=2.5)
2.5*33
ggplot(amakihi[amakihi$distance<82.5,], aes(x=distance)) +
geom_histogram(binwidth=8.25, colour="black", fill="white")
# Import Amakihi data
amakihi <- read.csv(file="https://synergy.st-andrews.ac.uk/ds-manda/files/2016/11/amakihi.csv")
library(ggplot2)
# Histogram with lots of bins and no truncation
ggplot(amakihi, aes(x=distance)) + geom_histogram(binwidth=1, colour="black", fill="white")
# hist(amakihi$distance, breaks=seq(0,260), main="No truncation",xlab = "Distance (m)")
# Histogram with lots of bins and truncation at 82.5
ggplot(amakihi[amakihi$distance<82.5,], aes(x=distance)) +
geom_histogram(binwidth=2.5, colour="black", fill="white")
# hist(amakihi$distance[amakihi$distance<82.5], breaks=33, main="Truncation 82.5",xlab = "Distance (m)")
# Truncate at 82.5 with fewer bins
# hist(amakihi$distance[amakihi$distance<82.5], breaks=10,
#     main="Truncation 82.5, fewer bins",xlab = "Distance (m)")
ggplot(amakihi[amakihi$distance<82.5,], aes(x=distance)) +
geom_histogram(binwidth=8.25, colour="black", fill="white")
install.packages("binb")
library(Distance)
monteverde <- read.csv("C:/Users/eric/Documents/GitHub/stand-intermed-2018/R_tutorial/ducknests.csv")
actual <- FALSE
monteverde$Area <- ifelse(actual, 45.199339, 50.000000) #km
monteverde$Effort <- 128.750 #km
est.hn <- ds(data=monteverde, key='hn',
convert.units = .001) # m to km
summary(est.hn)
summary(est.hn)
plot(est.hn)
install.packages(c("nloptr", "rstudioapi"))
library(Distance)
args(gof_ds)
setwd("~/GitHub/online-course-2018/exercisepdfs/Ch7")
knitr::opts_chunk$set(echo = TRUE)
# Specify whether answers are shown
answer <- TRUE
# Load library
library(Distance)
nests <- read.csv(file="datasets/ducks-area-effort.csv", header=TRUE)
nest.model1 <- ds(nests, key="hn", adjustment=NULL, convert.units = 0.001)
str(nest.model1$dht$individuals)
View(nest.model1)
knitr::kable(nest.model1$dht$individuals$summary)
knitr::kable(nest.model1$dht$individuals$N)
knitr::kable(nest.model1$dht$individuals$D)
nest.model1$dht$individuals$summary
nest.model1$dht$individuals
str(nest.model1$dht$individuals)
str(nest.model1$dht$individuals, max=1)
summary(nest.model1)
summary(nest.model1$dht)
nest.model1$dht$individuals$summary
nest.model1$dht$individuals$bysample$n
nest.model1$dht$individuals$summary$n
nest.model1$dht$individuals$summary$CoveredArea
nest.model1$dht$individuals$average.p
install.packages("plotrix")
