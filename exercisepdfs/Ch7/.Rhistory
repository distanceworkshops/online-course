check_exer_1_v3("sort(rep(1:4, 3))")
check_exer_1_v3("x <- 1:4; rep(x, each = 3)")
check_exer_1_v3("rep(c(1,2,3,4), each=3)")
s1 <- quote(Circuits <- read.csv("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s2 <- quote(Circuits <- load("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s3 <- quote(read.csv("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s4 <- quote(bees <- read.csv("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s1
eval(s1)
rm(s1)
rm(Circuits)
s1 <- quote(Circuits <- read.csv("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s2 <- quote(Circuits <- load("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s3 <- quote(read.csv("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
s4 <- quote(bees <- read.csv("http://www.lock5stat.com/datasets/HoneybeeCircuits.csv"))
check_bee_data <- function(USER_CODE) {
code <- for_checkr(USER_CODE)
# The messages
m1 <- "Right!"
m2 <- "Notice that the filename has a CSV extension. `{{F}}` is for reading RDA files. Try `read.csv()` instead."
m3 <- "Remember to store the contents of the data file under the name `Circuits`."
m4 <- "Store the data under the name `Circuits`, not `{{Z}}`."
browser()
result <- line_where(code,
passif(Z == "Circuits"),
failif(Z == "", m3),
failif(TRUE, m4))
return(result) # return the result of the checking
}
check_bee_data(s3)
result
check_bee_data(s4)
result
check_bee_data(s2)
result
install.packages("tinytex")
monteverde <- read.csv("C:/Users/eric/Documents/GitHub/stand-intermed-2018/R_tutorial/ducknests.csv")
monteverde$Area <- 45199339
est.hn <- ds(data=monteverde, key='hn')
library(Distance)
monteverde$Area <- 45199339
est.hn <- ds(data=monteverde, key='hn')
head(monteverde)
monteverde$Effort <- 1000
est.hn <- ds(data=monteverde, key='hn')
summary(est.hn)
20000*4.8
monteverde$Effort <- 128750
est.hn <- ds(data=monteverde, key='hn')
head(monteverde)
summary(est.hn)
source('~/.active-rstudio-document', echo=TRUE)
est.hn <- ds(data=monteverde, key='hn',
convert.units = .001)
head(monteverde)
summary(est.hn)
est.hn <- ds(data=monteverde, key='hn',
convert.units = .000001)
summary(est.hn)
est.hn <- ds(data=monteverde, key='hn',
convert.units = 1)
summary(est.hn)
source('~/.active-rstudio-document', echo=TRUE)
str(est.hn$ddf$ds$par)
exp(est.hn$ddf$ds$par)
exp(est.hn$ddf$ds$par) * 3.28084
install.packages(c("car", "digest"))
install.packages(c("callr", "plotrix", "wordcloud"))
install.packages(c("ggpubr", "tinytex", "xtable"))
install.packages(c("chron", "later"))
library(Distance)
data(minke)
View(minke)
minke.strat <- ds(data=minke, formula=~Region.Label)
summary(minke.strat)
summary(minke.strat)
pooled <- ds(data=minke)
summary(pooled)
exp(-.3514199)
library(readdst)
strat <- convert_project("C:/Users/eric/Documents/stratify-testbed/Stratify example")
R
version
library(Distance)
summary(ds(data=minke))
data(minke)
summary(ds(data=minke))
install.packages(c("digest", "whoami", "xts"))
julaugsep <- read.csv("P:/Distance 7.2 download form.csv")
View(julaugsep)
multi <- julaugsep[(duplicated(julaugsep$`E-mail address`, fromLast = FALSE) |
duplicated(julaugsep$`E-mail address`, fromLast = TRUE)),]
sorted <- multi[order(multi$`E-mail address`),]
sorted$timediff <- 0
mmm <- diff(sorted$Timestamp)
View(multi)
multi <- julaugsep[(duplicated(julaugsep$`E-mail address`, fromLast = FALSE) |
duplicated(julaugsep$`E-mail address`, fromLast = TRUE)),]
sorted <- multi[order(multi$`E-mail address`),]
View(multi)
names(julaugsep)
multi <- julaugsep[(duplicated(julaugsep$E.mail.address, fromLast = FALSE) |
duplicated(julaugsep$E.mail.address, fromLast = TRUE)),]
sorted <- multi[order(multi$E.mail.address),]
sorted$timediff <- 0
mmm <- diff(sorted$Timestamp)
mmm
julaugsep <- read.csv("P:/Distance 7.2 download form.csv", stringsAsFactors = FALSE)
multi <- julaugsep[(duplicated(julaugsep$E.mail.address, fromLast = FALSE) |
duplicated(julaugsep$E.mail.address, fromLast = TRUE)),]
sorted <- multi[order(multi$E.mail.address),]
sorted$timediff <- 0
mmm <- diff(sorted$Timestamp)
View(sorted)
library(lubridate)
library(readxl)
library(lubridate)
julaugsep <- read_xlsx("P:/Distance 7.2 download form.xlsx", stringsAsFactors = FALSE)
julaugsep <- read_xlsx("P:/Distance 7.2 download form.xlsx")
multi <- julaugsep[(duplicated(julaugsep$E.mail.address, fromLast = FALSE) |
duplicated(julaugsep$E.mail.address, fromLast = TRUE)),]
names(julaugsep)
multi <- julaugsep[(duplicated(julaugsep$`E-mail address`, fromLast = FALSE) |
duplicated(julaugsep$`E-mail address`, fromLast = TRUE)),]
sorted <- multi[order(multi$`E-mail address`),]
sorted$timediff <- 0
mmm <- diff(sorted$Timestamp)
View(sorted)
str(julaugsep)
mmm <- diff(sorted$Timestamp)
str(ssorted)
str(sorted)
julaugsep <- read_xlsx("P:/Distance 7.2 download form.xlsx",
col_types = c("date", "text", "skip", "text", "skip", "skip"))
warnings()
View(julaugsep)
julaugsep <- read_xlsx("P:/Distance 7.2 download form.xlsx")
julaugsep <- read_xlsx("P:/Distance 7.2 download form.xlsx")
julaugsep$time <- strptime(julaugsep$Timestamp, "%m/%d/%y %H:%M:%S")
View(julaugsep)
julaugsep$time <- strptime(substr(julaugsep$Timestamp, start = 1, stop = 10), "%m/%d/%y %H:%M:%S")
View(julaugsep)
julaugsep$time <- strptime(substr(julaugsep$Timestamp, start = 1, stop = 19), "%m/%d/%y %H:%M:%S")
strptime(substr(julaugsep$Timestamp, start = 1, stop = 19), "%m/%d/%y %H:%M:%S")
substr(julaugsep$Timestamp, start = 1, stop = 19)
tom <- substr(julaugsep$Timestamp, start = 1, stop = 19)
julaugsep$time <- strptime(substr(julaugsep$Timestamp, start = 1, stop = 10), "%y/%m/%d %H:%M:%S")
View(julaugsep)
julaugsep$time <- strptime(substr(julaugsep$Timestamp, start = 1, stop = 10), "%Y/%m/%d %H:%M:%S")
head(tom)
julaugsep$time <- strptime(substr(julaugsep$Timestamp, start = 1, stop = 19), "%Y/%m/%d %H:%M:%S ")
View(julaugsep)
multi <- julaugsep[(duplicated(julaugsep$`E-mail address`, fromLast = FALSE) |
duplicated(julaugsep$`E-mail address`, fromLast = TRUE)),]
sorted <- multi[order(multi$`E-mail address`),]
sorted$timediff <- 0
mmm <- diff(sorted$time)
mmm
sorted$timediff[2:280] <- mmm
View(sorted)
sorted$timediff[2:281] <- mmm
sorted$timediff <- ifelse(sorted$timediff<0, NA, sorted$timediff)
View(sorted)
sorted$timediff[c(1,3,7,9,11,13,15,17,19,21,23,25,31,33,35,41,43,46,48,
50,52,54,56,58,60,62,65,67,70,72,74,78,80,83,87,89,91,93,95,
97,99,101,103,105,107,109,112,116,118,121,123,126,128,130,132,134,136,138,141,
143,145,147,150,152,154,156,158,160,132,134,166,168,171,173,175,177,180,182,184,187,
189,193,195,197,199,201,203,207,209,211,213,216,218,223,225,228,230,232,235,
237,239,242,244,246,248,250,252,254,256,258,260,262,264,267,269,271,274,276,280)] <- NA   # first downloads by individual
timespan <- as.numeric(round(max(julaugsep$Timestamp)-min(julaugsep$Timestamp)), units="days")
timespan <- as.numeric(round(max(julaugsep$time)-min(julaugsep$time)), units="days")
downloads <- length(julaugsep$time)
downloads.per.day <- downloads/timespan
persons <- length(unique(julaugsep$`E-mail address`))
fast.double.download <- sorted$`E-mail address`[!is.na(sorted$timediff) & sorted$timediff<15]    # number of subsequent downloads within half hour of first
pct.double.down <- round(length(fast.double.download)/length(unique(julaugsep$`E-mail address`)) * 100, 1)
leg <- c("Total downloads",
"Downloads per day",
"Unique downloads",
"Second download within 15min",
"Percent second download")
stats <- c(downloads, round(downloads.per.day,2),
persons, length(fast.double.download), pct.double.down)
output <- data.frame(leg,stats)
knitr::kable(output, caption="Distance 7.2 download statistics")
hist(sorted$timediff)
fast.double.download <- sorted$`E-mail address`[!is.na(sorted$timediff) & sorted$timediff<900]    # number of subsequent downloads within half hour of first
pct.double.down <- round(length(fast.double.download)/length(unique(julaugsep$`E-mail address`)) * 100, 1)
leg <- c("Total downloads",
"Downloads per day",
"Unique downloads",
"Second download within 15min",
"Percent second download")
stats <- c(downloads, round(downloads.per.day,2),
persons, length(fast.double.download), pct.double.down)
output <- data.frame(leg,stats)
knitr::kable(output, caption="Distance 7.2 download statistics")
hist(sorted$/900)
hist(sorted$timediff/900)
install.packages("odbc")
install.packages(c("tm", "tm.plugin.mail"))
source('~/.active-rstudio-document', echo=TRUE)
zog <- all.sent[[1:10]]
all.sent[[1]]
all.sent[[1]]$content
all.sent[[1]]$meta$datetimestamp
library(lubridate)
bob <- all.sent$meta$datestamp > "2018-06-01"
bob
all.sent[[8000]]$meta$datetimestamp
bob <- all.sent[8000:8334]
View(bob)
bob$meta$author
bob$content
bob[[]]$content
tmp <- lapply(unlist(summer,recursive=FALSE), `[[`,2)
summer <- all.sent[8000:8334]
tmp <- lapply(unlist(summer,recursive=FALSE), `[[`,2)
View(tmp)
tm2 <- lapply(unlist(tmp), `[[`, `header`)
tm2 <- lapply(unlist(tmp), `[[`, `heading`)
tm2 <- lapply(unlist(tmp), `[[`, "heading")
tm2 <- lapply(unlist(tmp), `[[`, 4)
tm2 <- lapply(unlist(tmp), `[`, 4)
tm2
View(tmp)
tm2 <- lapply(unlist(tmp), `[[`, 4)
tm2 <- lapply(tmp, `[[`, 4)
View(tm2)
tmp <- lapply(unlist(summer,recursive=FALSE), `[[`,2)
tm2 <- unlist(lapply(tmp, `[[`, 4))
tm2[1:5]
str(tm2)
tm2 <- unname(unlist(lapply(tmp, `[[`, 4)))
head(tm2)
library(tm)
library(tm.plugin.mail)
# point the tm corpus machinery to the mbox file and let it know the timestamp format since it varies
all.sent <- VCorpus(
MBoxSource("C:/Users/eric/empty/sent"),
readerControl = list(
reader = readMail()
)
)
all.sent[[8100]]$content
all.sent.nosig <- removeSignature(all.sent)
class(all.sent)
nosig <- lapply(all.sent, FUN=removeSignature(x))
nosig <- lapply(all.sent, function(x) removeSignature(x))
nosig[[8100]]$content
nocitation <- lapply(all.sent, function(x) removeCitation(x))
nocitation[[8100]]$content
nomult <- lapply(all.sent, function(x) removeMultipart(x))
nomult[[8100]]$content
nomultsig <- lapply(nomult, function(x) removeSignature(x))
nomultsig[[8100]]$content
none <- lapply(nomultsig, function(x) removeCitation(x))
none[[8100]]$content
?save
getwd()
none[[8100]]$meta$header$To
save(none, file = "office-sent.Rdata")
getwd()
library(rmarkdown)
draft("myslides.Rmd", template="metropolis", package="binb", edit=FALSE)
getwd()
library(tint)
install.packages(c("ape", "cli", "doParallel"))
getwd()
!TRUE
library(ggplot2)
# Import Amakihi data
amakihi <- read.csv(file="https://synergy.st-andrews.ac.uk/ds-manda/files/2016/11/amakihi.csv")
# Basic histogram
ggplot(amakihi, aes(x=distance)) + geom_histogram(binwidth=1)
# Histogram with lots of bins and truncation at 82.5
ggplot(amakihi[amakihi$distance<82.5], aes(x=distance)) +
geom_histogram(binwidth=2.5)
hist(amakihi$distance[amakihi$distance<82.5,], breaks=33, main="Truncation 82.5",xlab = "Distance (m)")
# Histogram with lots of bins and truncation at 82.5
ggplot(amakihi[amakihi$distance<82.5,], aes(x=distance)) +
geom_histogram(binwidth=2.5)
2.5*33
ggplot(amakihi[amakihi$distance<82.5,], aes(x=distance)) +
geom_histogram(binwidth=8.25, colour="black", fill="white")
# Import Amakihi data
amakihi <- read.csv(file="https://synergy.st-andrews.ac.uk/ds-manda/files/2016/11/amakihi.csv")
library(ggplot2)
# Histogram with lots of bins and no truncation
ggplot(amakihi, aes(x=distance)) + geom_histogram(binwidth=1, colour="black", fill="white")
# hist(amakihi$distance, breaks=seq(0,260), main="No truncation",xlab = "Distance (m)")
# Histogram with lots of bins and truncation at 82.5
ggplot(amakihi[amakihi$distance<82.5,], aes(x=distance)) +
geom_histogram(binwidth=2.5, colour="black", fill="white")
# hist(amakihi$distance[amakihi$distance<82.5], breaks=33, main="Truncation 82.5",xlab = "Distance (m)")
# Truncate at 82.5 with fewer bins
# hist(amakihi$distance[amakihi$distance<82.5], breaks=10,
#     main="Truncation 82.5, fewer bins",xlab = "Distance (m)")
ggplot(amakihi[amakihi$distance<82.5,], aes(x=distance)) +
geom_histogram(binwidth=8.25, colour="black", fill="white")
install.packages("binb")
library(Distance)
monteverde <- read.csv("C:/Users/eric/Documents/GitHub/stand-intermed-2018/R_tutorial/ducknests.csv")
actual <- FALSE
monteverde$Area <- ifelse(actual, 45.199339, 50.000000) #km
monteverde$Effort <- 128.750 #km
est.hn <- ds(data=monteverde, key='hn',
convert.units = .001) # m to km
summary(est.hn)
summary(est.hn)
plot(est.hn)
install.packages(c("fansi", "nloptr", "R6", "secr", "spatstat.data"))
xbill <- read.csv(file="datasets/lure-trials.csv", header=TRUE)
setwd("~/GitHub/online-course-2018/exercisepdfs/Ch7")
xbill <- read.csv(file="datasets/lure-trials.csv", header=TRUE)
names(xbill)
# Chunk 1
library(knitr)
answer <- TRUE
# Chunk 2
\includeimage []{crossbill_lure-300x247.jpg}
A call station to lure Scottish crossbills _(Loxia scotica)_.
# Chunk 3
xbill <- read.csv(file="datasets/lure-trials.csv", header=TRUE)
# Chunk 4
head(xbill, n=2)
# Chunk 5
table(xbill$response)
# Chunk 6
xbill$habitat <- factor(xbill$habitat)
xbill$behavcode <- factor(xbill$behavcode)
# Chunk 7
addmargins(table(xbill$response, xbill$habitat))
# Chunk 8
# Divide plot window into 4
par(mfrow=c(2,2))
# Boxplots for each covariate
boxplot(xbill$dist~xbill$response, xlab="Response", ylab="Distance (m)")
boxplot(xbill$numbirds~xbill$response, xlab="Response", ylab="Flock size")
boxplot(xbill$day~xbill$response, xlab="Response", ylab="Days from 1 Jan")
boxplot(xbill$time~xbill$response, xlab="Response", ylab="Hour of day")
# Chunk 9
__Answer:__ Qualitatively, these boxplots suggest little difference in crossbill behaviour in response to the lure attributable to flock size or time of day.  There may be more influence of distance and date upon response to lure.  Models will be fitted to make stronger inference.
# Chunk 10
# Fit a model with all potential covars
model1 <- glm(response~dist+numbirds+day+time+habitat+behavcode, family=binomial,
data=xbill)
# Chunk 11
summary(model1)
# Chunk 12
# Fit model with dist only
model2 <- glm(response~dist, family=binomial, data=xbill)
# Chunk 13
summary(model2)
# Chunk 14
# Specify maximum distance
w <- 850
# Create data frame containing distances
preddata <- data.frame(dist=0:w)
# Predicton
phat <- predict.glm(model2, newdata=preddata, type="response")
# Chunk 15
plot(xbill$dist, xbill$response, xlim=c(0, w), xlab="Distance from lure (m)",
ylab="Probability of response")
lines(preddata$dist, phat, col="red")
# Chunk 16
# Create pdf
pi.r <- preddata$dist/sum(preddata$dist)
plot(preddata$dist, pi.r, xlab="Distance from lure")
# Chunk 17
# Calculate Pa
Pa <- sum(phat * pi.r)
print(Pa)
# Chunk 18
detections <- read.csv("datasets/mainsurveydetections.csv", header=TRUE)
# Total number of Scottish crossbills detected
n <- sum(detections$nscottish)
# Chunk 19
k <- length(detections$point)
# Covered area (km2)
a <- k * pi * (w/1000)^2
# Size of the study region (km2)
A <- 3505.8
# Chunk 20
Nscot <- (n*A)/(Pa*a)
# Chunk 21
print(Nscot)
# Initialise parameters
# Number of bootstraps
nboot <- 999
# Number of trials
m <- length(xbill$dist)
# Create empty vectors to store new sample
bdistances <- vector(length=m)
bresponse <- vector(length=m)
# Create empty vector to store bootstrap abundances
bNscot <- vector(length=nboot)
# Create prediction data (w is truncation distance defined earlier)
pred <- data.frame(bdistances=0:w)
# A loop for the bootstraps
for (i in 1:nboot) {
# Bootstrap trials
# Generate index of sample
btindex <- sample(1:m, size=m, replace=TRUE)
for (j in 1:m) {
bdistances[j] <- xbill$dist[btindex[j]]
bresponse[j] <- xbill$response[btindex[j]]
}
# Fit GLM
bmodel <- glm(bresponse ~ bdistances, family=binomial)
# Predict probability of response
bphat <- predict.glm(bmodel, newdata=pred, type="response")
# Calculate Pa
bPa <- sum(bphat * pi.r)
# Bootstrap points
rindex <- sample(1:k, k, replace=TRUE)
n <- sum(detections$nscottish[rindex])
# Calculate abundance
bNscot[i] <- (n*A)/(bPa*a)
} # End of bootstrap loop
quantile(bNscot, probs=c(0.025, 0.975))
hist(bNscot)
abline(v=quantile(bNscot, probs=c(0.025, 0.975)))
?plotmath
par(mfrow)=c(1,1)
par(mfrows)=c(1,1)
?par
par(mfrow=c(1,1))
plot(1:10, 1:10, ylab=expression(pi.r))
plot(1:10, 1:10, ylab=expression(pi_r))
x <- seq(-4, 4, len = 101)
y <- cbind(sin(x), cos(x))
matplot(x, y, type = "l", xaxt = "n",
main = expression(paste(plain(sin) * phi, "  and  ",
plain(cos) * phi)),
ylab = expression("sin" * phi, "cos" * phi), # only 1st is taken
xlab = expression(paste("Phase Angle ", phi)),
col.main = "blue")
axis(1, at = c(-pi, -pi/2, 0, pi/2, pi),
labels = expression(-pi, -pi/2, 0, pi/2, pi))
plot(1:10, 1:10, ylab=expression(pi))
plot(1:10, 1:10, ylab=expression(pi[r]))
alpha <- 0.05
bounds <- c(alpha/2, 1-(alpha/2))
hist(bNscot)
abline(v=quantile(bNscot, probs=bounds))
mean(bNscot)
library(ggplot2)
ggplot(data=bNscot, aes(bNscot)) + geom_histogram(fill="white") +
labs(title="Distribution of replicate abundance estimates") +
labs(x=expression(hat(N)), y="Count") =
geom_vline(xintercept=quantile(bNscot, probs=bounds), size=2)
ggplot(aes(bNscot)) + geom_histogram(fill="white") +
labs(title="Distribution of replicate abundance estimates") +
labs(x=expression(hat(N)), y="Count") =
geom_vline(xintercept=quantile(bNscot, probs=bounds), size=2)
ggplot() + aes(bNscot) + geom_histogram(fill="white") +
labs(title="Distribution of replicate abundance estimates") +
labs(x=expression(hat(N)), y="Count") =
geom_vline(xintercept=quantile(bNscot, probs=bounds), size=2)
?fortify
bob <- fortify(bNscot)
bob <- fortify(model=bNscot)
bob <- as.data.frame(bNscot)
str(bob)
ggplot(data=as.data.frame(bNscot) + aes(bNscot) + geom_histogram(fill="white") +
labs(x=expression(hat(N)), y="Count") =
ggplot(data=as.data.frame(bNscot) + aes(bNscot)) + geom_histogram(fill="white") +
labs(title="Distribution of replicate abundance estimates") +
labs(x=expression(hat(N)), y="Count") =
geom_vline(xintercept=quantile(bNscot, probs=bounds), size=2)
ggplot(data=as.data.frame(bNscot) + aes(bNscot)) + geom_histogram(fill="white")
plot.this <- as.data.frame(bNscot)
ggplot(data=plot.this + aes(bNscot)) + geom_histogram(fill="white") +
labs(title="Distribution of replicate abundance estimates") +
labs(x=expression(hat(N)), y="Count") =
geom_vline(xintercept=quantile(bNscot, probs=bounds), size=2)
str(plot.this)
ggplot(data.frame(x=bNscot) + aes(x)) + geom_histogram(fill="white") +
labs(title="Distribution of replicate abundance estimates") +
labs(x=expression(hat(N)), y="Count") =
geom_vline(xintercept=quantile(bNscot, probs=bounds), size=2)
ggplot(data=data.frame(x=bNscot) + aes(x)) + geom_histogram(fill="white") +
labs(title="Distribution of replicate abundance estimates") +
labs(x=expression(hat(N)), y="Count") =
geom_vline(xintercept=quantile(bNscot, probs=bounds), size=2)
ggplot(data=plot.this + aes(x)) + geom_histogram(fill="white") +
labs(title="Distribution of replicate abundance estimates") +
labs(x=expression(hat(N)), y="Count") =
geom_vline(xintercept=quantile(bNscot, probs=bounds), size=2)
ggplot(data=plot.this, aes(bNscot)) + geom_histogram(fill="white") +
labs(title="Distribution of replicate abundance estimates") +
labs(x=expression(hat(N)), y="Count") =
geom_vline(xintercept=quantile(bNscot, probs=bounds), size=2)
ggplot(data=plot.this, aes(bNscot)) + geom_histogram(fill="white")
ggplot(data=plot.this, aes(bNscot)) + geom_histogram(fill="white", colour="black") +
labs(title="Distribution of replicate abundance estimates")
ggplot(data=plot.this, aes(bNscot)) + geom_histogram(fill="white", colour="black") +
labs(title="Distribution of replicate abundance estimates") +
labs(x=expression(hat(N)), y="Count") +
geom_vline(xintercept=quantile(bNscot, probs=bounds), size=2)
ggplot(data=plot.this, aes(bNscot)) + geom_histogram(fill="white", colour="black") +
labs(title="Distribution of replicate abundance estimates") +
labs(x=expression(hat(N)), y="Count") +
geom_vline(xintercept=quantile(bNscot, probs=bounds), size=1.5, linetype="dotted")
ggplot(data=xbill, aes(x=dist, y=response)) + geom_point(shape=1) +
stat_smooth(method="glm", family="binomial")
ggplot(data=xbill, aes(x=dist, y=response)) + geom_point(shape=1) +
geom_smooth(method="glm", method.args=list(family="binomial"))
ggplot(data=preddata, aes(x=dist, y=pi.r)) + geom_point() +
labs(title="Assumed density of birds at given distance from point") +
labs(x="Distance from lure (m)", y=expression(pi[r]))
